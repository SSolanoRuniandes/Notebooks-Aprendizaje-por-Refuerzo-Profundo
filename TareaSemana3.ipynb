{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SSolanoRuniandes/Notebooks-Aprendizaje-por-Refuerzo-Profundo/blob/main/TareaSemana3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "![MAIA banner](https://raw.githubusercontent.com/MAIA4361-Aprendizaje-refuerzo-profundo/Notebooks_Tareas/main/Images/Aprendizaje_refuerzo_profundo_Banner_V1.png)\n",
        "\n",
        "# <h1><center>Tarea Tutorial - Semana 3 <a href=\"https://colab.research.google.com/github/SSolanoRuniandes/Notebooks-Aprendizaje-por-Refuerzo-Profundo/blob/main/TareaSemana3.ipynb\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" width=\"140\" align=\"center\"/></a></center></h1>\n",
        "\n",
        "<center><h1>Deep Q Networks</h1></center>\n",
        "\n",
        "En este tutorial...\n",
        "\n",
        "\n",
        "# Tabla de Contenidos\n",
        "1. [Objetivos de Aprendizaje](#scrollTo=Objetivos_de_Aprendizaje)  \n",
        "2. [Marco Teórico](#scrollTo=Marco_Te_rico)  \n",
        "3. [Instalación de Librerías](#scrollTo=Instalaci_n_de_Librer_as)  \n",
        "4. [Familiarización con el Entorno de Gym](#scrollTo=Familiarizaci_n_con_el_Entorno_de_Gym)  \n",
        "5. [DQN](#scrollTo=DQN)\n",
        "6. [Doble DQN](#scrollTo=Doble_DQN)  \n",
        "7. [Experience Replay](#scrollTo=Experience_Replay)  \n",
        "8. [Reflexiones Finales](#scrollTo=Reflexiones_Finales)  \n",
        "9. [Referencias](#scrollTo=Referencias)"
      ],
      "metadata": {
        "id": "oblzmhF6SCZW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objetivos de Aprendizaje  \n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "k8OPdsC0AxgP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Marco Teórico  \n"
      ],
      "metadata": {
        "id": "9lCj3GovPOcA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Instalación de Librerías  \n",
        "\n",
        "...\n"
      ],
      "metadata": {
        "id": "chWp-3WSPQlU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Descarga librerías no incluidas en Colab usando pip\n",
        "!pip install stable_baselines3 #Stable Baselines3 -> Framework de Reinforcement Learning\n",
        "!pip install gymnasium #Gym -> Contiene ambientes como CartPole\n",
        "!pip install renderlab #usado para renderizar gym\n",
        "\n",
        "#Importa estas librerías\n",
        "import stable_baselines3 #importa Stable Baselines3\n",
        "from stable_baselines3 import DQN #importa el agente/algoritmo de DQN\n",
        "from stable_baselines3.common.logger import configure #importa herramientas de logger/debug\n",
        "from stable_baselines3.common.logger import Logger, CSVOutputFormat, HumanOutputFormat #importa herramientas de logger/debug\n",
        "from stable_baselines3.common.evaluation import evaluate_policy #importa herramienta de evaluación automática\n",
        "import gymnasium as gym #importa la libreria de gym con las simulaciones\n",
        "import renderlab #importa renderlab para los videos\n",
        "\n",
        "#Importa otras librerías básicas\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import math\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "#Limpia los registros generados\n",
        "from IPython.display import clear_output\n",
        "clear_output()\n",
        "print(\"Todas las librerías han sido instaladas correctamente.\")"
      ],
      "metadata": {
        "id": "Lt7lZo5UB-Nh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8cf65ab-5f6b-4c42-b43c-52a59bc6810a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Todas las librerías han sido instaladas correctamente.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Familiarización con el Entorno de Gym\n",
        "\n",
        "El ambiente de Gym de <a href=\"https://gymnasium.farama.org/environments/classic_control/cart_pole/\">Cart Pole</a> consiste de un carrito que debe moverse a la izquierda o a la derecha para intentar balancear un poste que tiene en la parte superior. Puede leer más detalladamente la documentación de este ambiente en los foros oficiales de Gymnasium.\n",
        "\n",
        "![Observation_space_cartpole](https://raw.githubusercontent.com/SSolanoRuniandes/Notebooks-Aprendizaje-por-Refuerzo-Profundo/main/Images/Observation_space_cartpole.png)\n",
        "\n",
        "<center>Figura 4. Espacio de observación del ambiente de <i>CartPole</i>. [3]</center>\n",
        "\n",
        "El ambiente está definido por un estado continuo en 4 dimensiones, que definen posición y velocidad del carrito, y posición y velocidad angular del poste. Por otro lado, sólo hay dos acciones posibles: 0 el carrito se mueve a la izquierda, y 1 el carrito va a la derecha. La meta es evitar que el poste caiga por el mayor tiempo posible, por lo que en cada paso de la simulación que el poste no caiga se obtiene recompensa +1. Si el poste sale del rango [-12°, 12°], el episodio se da por terminado, mientras que si el episodio supera los 500 pasos, se da por truncado; en ambos casos se finaliza la simulación.\n",
        "\n",
        "Esto quiere decir que el retorno sin descuento máximo que se podría obtener en una simulación es de 500."
      ],
      "metadata": {
        "id": "xdQ5A4KbPSOu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejemplo\n",
        "\n",
        "...."
      ],
      "metadata": {
        "id": "1CxFdNryYVwy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ejemplo de simulación de un episodio de CartPole\n",
        "\n",
        "env_prueba_1 = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\") #Esta línea de código crea el ambiente.\n",
        "env_prueba_1 = renderlab.RenderFrame(env_prueba_1, \"./output\") #Esta línea se utiliza para crear una copia que se pueda renderizar con renderlab\n",
        "\n",
        "obs , info = env_prueba_1.reset() #Se reinicia el estado para comenzar. En obs se almacena el estado observado (continuo, 4 dimensiones)\n",
        "terminated = False #Inicializa una condición para el loop\n",
        "truncated = False #Inicializa una condición para el loop\n",
        "total_reward=0 #Inicializa contador del retorno\n",
        "\n",
        "while not (terminated or truncated): #Simula hasta que el poste caiga o hasta alcanzar 500 episodios (configuración de CartPole-v1)\n",
        "  action=0 #Decide una acción. En este caso, siempre va a la izquierda\n",
        "  obs, reward, terminated, truncated , info = env_prueba_1.step(action) #Con la función step el ambiente da un paso. Se obtiene el estado, recompensa y banderas de información\n",
        "  total_reward+=reward #Llevamos una cuenta de la recompensa total\n",
        "\n",
        "print(\"Recompensa obtenida en el episodio:\",total_reward) #Después de terminar el episodio, imprimios la recompensa acumulada total obtenida\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "env_prueba_1.play() #Con esta función se obtiene el video de la simulación"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        },
        "id": "2CB_sJpPOoJZ",
        "outputId": "3eba444b-2ff0-4c00-9cd1-3d08ce7f01ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recompensa obtenida en el episodio: 9.0\n",
            "\n",
            "\n",
            "\n",
            "Moviepy - Building video temp-{start}.mp4.\n",
            "Moviepy - Writing video temp-{start}.mp4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "                                                   "
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Moviepy - Done !\n",
            "Moviepy - video ready temp-{start}.mp4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Video object>"
            ],
            "text/html": [
              "<video controls  >\n",
              " <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\">\n",
              " Your browser does not support the video tag.\n",
              " </video>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ejercicio práctico\n",
        "..."
      ],
      "metadata": {
        "id": "lMfeVnMCb7wY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Simulación\n",
        "\n",
        "# =====================================================\n",
        "# COMPLETAR ===========================================\n",
        "#\n",
        "\n",
        "# ====================================================="
      ],
      "metadata": {
        "id": "Ev_RAlPacrEk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#DQN"
      ],
      "metadata": {
        "id": "Dgll1rHuRXUM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doble DQN"
      ],
      "metadata": {
        "id": "Ox7ADKspRcuB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Experience Replay"
      ],
      "metadata": {
        "id": "CPC-fgKaRXab"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Reflexiones Finales\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "G5ZVj1xuPWoo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Referencias\n",
        "\n",
        "[1] Sutton, R. S. and Barto, A. G. (2018). Reinforcement Learning: An Introduction. The MIT Press, second edition.\n",
        "\n",
        "[2] Mnih, V., Kavukcuoglu, K., Silver, D., Graves, A., Antonoglou, I., Wierstra, D., and Riedmiller, M. (2013). Playing atari with deep reinforcement learning. cite arxiv:1312.5602Comment: NIPS Deep Learning Workshop 2013.\n",
        "\n",
        "[3] Gym Documentation, Cart Pole. `https://www.gymlibrary.dev/environments/classic_control/cart_pole/`\n",
        "\n",
        "[4] Stable Baselines3 Documentation, DQN. `https://stable-baselines3.readthedocs.io/en/master/modules/dqn.html`"
      ],
      "metadata": {
        "id": "HhVGfkzU6KRH"
      }
    }
  ]
}